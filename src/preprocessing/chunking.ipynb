{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd44056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thebi\\Desktop\\DocsGuide\\src\\projenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from typing import List\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import textwrap\n",
    "import npttf2utf\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7264403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f260048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal\n",
    "\n",
    "class Chunk(BaseModel):\n",
    "    chunk_id: int = Field(description=\"Sequential identifier (1, 2, 3...)\")\n",
    "    document_type: Literal[\"citizenship\"] = Field(description=\"Type of document, e.g., 'citizenship'\")\n",
    "    section: str = Field(description=\"दफा नम्बर (e.g., '3', '4')\")\n",
    "    subsection: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of उपदफा नम्बर; empty list if not present\"\n",
    "    )\n",
    "    tag: List[Literal[\n",
    "        \"eligibility & requirements\",\n",
    "        \"procedure\",\n",
    "        \"recommendation\",\n",
    "        \"legal\",\n",
    "        \"special case\",\n",
    "        \"correction & modification\"\n",
    "    ]] = Field(description=\"List of 2 tags at maximum best describing the content\")\n",
    "    references: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of mentioned Dafa or Upadafa numbers; empty if none\"\n",
    "    )\n",
    "    source_type:str = Field(description= \"Type of source for this chunk\")\n",
    "    source_link:str = Field(description = \"Source link\")\n",
    "    content: str = Field(description=\"Full Nepali Unicode text of the chunk\")\n",
    "\n",
    "class ChunkList(BaseModel):\n",
    "    chunks: List[Chunk] = Field(description=\"List of all structured chunks extracted from the document\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60beff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parser setup\n",
    "parser = JsonOutputParser(pydantic_object=ChunkList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14692995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(path):\n",
    "    pdf_path = rf\"{path}\"\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    docs = loader.load()\n",
    "    text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    \n",
    "    # Convert Preeti → Unicode\n",
    "    mapper = npttf2utf.FontMapper(\"map.json\")\n",
    "    output_text = mapper.map_to_unicode(\n",
    "        text,\n",
    "        from_font=\"Preeti\",\n",
    "        unescape_html_input=False,\n",
    "        escape_html_output=False\n",
    "    )\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57b69539",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=textwrap.dedent(\"\"\"\n",
    "    You are an expert legal document analyzer specialized in Nepali legal and administrative documents. \n",
    "    Your task is to extract, chunk, and structure information from the Nepal Citizenship Act document \n",
    "    into a JSON-ready schema suitable for vector database insertion.\n",
    "\n",
    "    1. CHUNK CREATION:\n",
    "    - If a dafa (section) is shorter than 150–200 words → create a single chunk for the entire dafa.\n",
    "    - Group multiple उपदफा together into a single chunk if their combined length does not exceed 150 words.\n",
    "    - NEVER break within an upadafa — always complete the current upadafa before creating a new chunk.\n",
    "                             \n",
    "    2. SCHEMA FIELDS:\n",
    "    Each extracted chunk must include the following fields strictly following the instruction:\n",
    "    - chunk_id: Sequential integer identifier (1, 2, 3…)\n",
    "    - document_type: \"citizenship\" (for this document)\n",
    "    - section: Dafa number (e.g., \"3\", \"4\", \"5\")\n",
    "    - subsection: subsection: List of Upadafa numbers of the content (e.g., \"1\", \"2\"); use [] if none\n",
    "    - tag: Assign maximum of two tags from the list below based on content meaning:\n",
    "        * \"eligibility & requirements\" (योग्यता र आवश्यक कागजातहरू): Age, relationship, residence, or document requirements\n",
    "        * \"procedure\" (प्रक्रिया): Steps for obtaining citizenship, application process, or office procedures\n",
    "        * \"recommendation\" (सिफारिस/मुचुल्का): Recommendations, certificates, or identification from ward or authority\n",
    "        * \"legal\" (कानुनी व्यवस्था र दण्ड): Legal provisions, rules, penalties, or implementation clauses\n",
    "        * \"special case\" (विशेष अवस्था): Exceptional or unusual citizenship circumstances\n",
    "        * \"correction & modification\" (संशोधन र सुधार): Name, surname, or birth-date corrections and related modifications\n",
    "    - references: List any mentioned or referenced Dafa or Upadafa numbers, e.g. [\"2(3)\", \"5(1)\"]; use [] if none.\n",
    "    - source_type:\"Citizenship_Act\"\n",
    "    - source_link:\"https://moha.gov.np/en/post/citizenship-act-2063\"\n",
    "    - content: The full Nepali text of the chunk (do not summarize or translate) or remove anything.\n",
    "\n",
    "    4. DOCUMENT STRUCTURE UNDERSTANDING:\n",
    "    - The document follows Dafa (section) and Upadafa (subsection) numbering (e.g., “दफा 5(1)”).\n",
    "    - Identify all dafa and upadafa correctly.\n",
    "    - Track cross-references between different Dafas (e.g., “दफा 2(3) अनुसार”) or implicit reference and include them in the `references` field.\n",
    "    - There may be improper uncodes in prompt so fix that too when generating response.\n",
    "\n",
    "    DOCUMENT TEXT:\n",
    "    {context}\n",
    "\n",
    "    {format_instructions}\n",
    "\n",
    "    Return ONLY valid JSON following the exact schema above.\n",
    "    \"\"\"),\n",
    "    input_variables=[\"context\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "prompt_multi = PromptTemplate(\n",
    "    template=textwrap.dedent(\"\"\"\n",
    "    You are an expert legal document analyzer specialized in Nepali legal and administrative documents. \n",
    "    Your task is to extract, chunk, and structure information from the Nepal Citizenship Act document \n",
    "    into a JSON-ready schema suitable for vector database insertion.\n",
    "\n",
    "    1. CHUNK CREATION:\n",
    "    - If a dafa (section) is shorter than 100 words → create a single chunk for the entire dafa.\n",
    "    - Group multiple उपदफा together into a single chunk if their combined length does not exceed 100 words.\n",
    "    - NEVER break within an upadafa — always complete the current upadafa before creating a new chunk.\n",
    "                             \n",
    "    2. SCHEMA FIELDS:\n",
    "    Each extracted chunk must include the following fields strictly following the instruction:\n",
    "    - chunk_id: Sequential integer identifier (1, 2, 3…)\n",
    "    - document_type: \"citizenship\" (for this document)\n",
    "    - section: Dafa number (e.g., \"3\", \"4\", \"5\")\n",
    "    - subsection: subsection: List of Upadafa numbers of the content (e.g., \"1\", \"2\"); use [] if none\n",
    "    - tag: Assign maximum of two tags from the list below based on content meaning:\n",
    "        * \"eligibility & requirements\" (योग्यता र आवश्यक कागजातहरू): Age, relationship, residence, or document requirements\n",
    "        * \"procedure\" (प्रक्रिया): Steps for obtaining citizenship, application process, or office procedures\n",
    "        * \"recommendation\" (सिफारिस/मुचुल्का): Recommendations, certificates, or identification from ward or authority\n",
    "        * \"legal\" (कानुनी व्यवस्था र दण्ड): Legal provisions, rules, penalties, or implementation clauses\n",
    "        * \"special case\" (विशेष अवस्था): Exceptional or unusual citizenship circumstances\n",
    "        * \"correction & modification\" (संशोधन र सुधार): Name, surname, or birth-date corrections and related modifications\n",
    "    - references: List any mentioned or referenced Dafa or Upadafa numbers, e.g. [\"2(3)\", \"5(1)\"]; use [] if none.\n",
    "    - source_type:\"Citizenship_Act\"\n",
    "    - source_link:\"https://moha.gov.np/en/post/citizenship-act-2063\"\n",
    "    - content: The full Nepali text of the chunk (do not summarize or translate) or remove anything.\n",
    "\n",
    "    4. DOCUMENT STRUCTURE UNDERSTANDING:\n",
    "    - The document follows Dafa (section) and Upadafa (subsection) numbering (e.g., “दफा 5(1)”).\n",
    "    - \"क\",\"ख\",\"ग\" these are not subsections. Subsections and sections are numerals.\n",
    "    - Identify all dafa and upadafa correctly.\n",
    "    - Track cross-references between different Dafas (e.g., “दफा 2(3) अनुसार”) or implicit reference and include them in the `references` field.\n",
    "    - Also track reference of upadafas within same dafa (e.g. उपदफा (१) बमोजिम )\n",
    "    - There may be improper uncodes in prompt so fix that too when generating response.\n",
    "\n",
    "    DOCUMENT TEXT:\n",
    "    {context}\n",
    "\n",
    "    {format_instructions}\n",
    "\n",
    "    Return ONLY valid JSON following the exact schema above.\n",
    "    \"\"\"),\n",
    "    input_variables=[\"context\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec6c6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thebi\\Desktop\\DocsGuide\\src\\projenv\\Lib\\site-packages\\pydantic\\json_schema.py:2442: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=True, description='List of उपदफा नम्बर of the content if not present'),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      "c:\\Users\\thebi\\Desktop\\DocsGuide\\src\\projenv\\Lib\\site-packages\\pydantic\\json_schema.py:2442: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=True, description='List of 1-2 tags from: eligibility & requirements, procedure, recommendation, legal, special case, correction & modification'),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      "c:\\Users\\thebi\\Desktop\\DocsGuide\\src\\projenv\\Lib\\site-packages\\pydantic\\json_schema.py:2442: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=True, description='List of mentioned Dafa or Upadafa numbers empty if none'),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n"
     ]
    }
   ],
   "source": [
    "prompt2 = PromptTemplate(\n",
    "    template=textwrap.dedent(\"\"\"\n",
    "    You are an expert legal document analyzer specialized in Nepali legal and administrative documents. \n",
    "    Your task is to extract, chunk, and structure information from the Nepal Citizenship Requirements PDF\n",
    "    into a JSON-ready schema suitable for vector database insertion.\n",
    "\n",
    "    1. a)Each chunk must correspond to **one specific citizenship type or situation**, such as:\n",
    "       - वंशजको नागरिकता (अविवाहित)\n",
    "       - अंगीकृत नागरिकता (वैवाहिक)\n",
    "       - प्रतिलिपि नागरिकता\n",
    "       - कर्मचारी परिवारको आधारमा\n",
    "       - पतिको नाम समावेश/हटाउने\n",
    "       - सम्बन्ध विच्छेद/दोस्रो विवाह\n",
    "                             \n",
    "      b) tag: Assign maximum of two tags from the list below based on content meaning:\n",
    "        * \"eligibility & requirements\" (योग्यता र आवश्यक कागजातहरू): Age, relationship, residence, or document requirements\n",
    "        * \"procedure\" (प्रक्रिया): Steps for obtaining citizenship, application process, or office procedures\n",
    "        * \"recommendation\" (सिफारिस/मुचुल्का): Recommendations, certificates, or identification from ward or authority\n",
    "        * \"legal\" (कानुनी व्यवस्था र दण्ड): Legal provisions, rules, penalties, or implementation clauses\n",
    "        * \"special case\" (विशेष अवस्था): Exceptional or unusual citizenship circumstances\n",
    "        * \"correction & modification\" (संशोधन र सुधार): Name, surname, or birth-date corrections and related modifications\n",
    "      c) references: List any mentioned or referenced सि.नं (write in english numeral)\n",
    "      d) section: section means the सि.नं (write in english numeral)\n",
    "      For each chunk :source_type:\"Citizenship_Prcoess\" and source_link:\"https://daodarchula.moha.gov.np/post/documents-required-for-citizenship-new\"\n",
    "                             \n",
    "    2. For each such chunk:\n",
    "       - Use `\"content\"` to include:\n",
    "         - A contextual summary starting with a sentence like:\n",
    "           **\"यदि कुनै व्यक्ति अविवाहित छन् र वंशजको आधारमा नेपाली नागरिकता प्राप्त गर्न चाहन्छन् भने, निम्न प्रक्रिया र कागजातहरू आवश्यक पर्छन्।\"**\n",
    "         - Followed by the required documents and procedures in bullet or numbered format.\n",
    "                             \n",
    "    3. If the document contains **portions that do NOT specify any citizenship type or situation**, then:\n",
    "       - Split semantically into chunks of approximately **150 words**\n",
    "       - Each chunk must begin with a **brief contextual summary in Nepali** describing what the section is about (e.g., टिकटको व्यवस्था, वसाई सराईको ध्यान दिनुपर्ने कुरा, कर्मचारी परिवारको सिफारिश प्रक्रिया)\n",
    "       - Do NOT split inside a bullet point or sentence; preserve semantic boundaries\n",
    "\n",
    "    4. The `\"content\"` must be written in clear, formal Nepali and be semantically complete — it should answer standalone queries like:\n",
    "       - \"के कागजात चाहिन्छ?\"\n",
    "       - \"कसको सिफारिश चाहिन्छ?\"\n",
    "       - \"कुन अवस्थामा यो प्रक्रिया लागू हुन्छ?\"\n",
    "\n",
    "    5. Do NOT merge multiple citizenship types into one chunk. Keep each chunk focused and self-contained.\n",
    "\n",
    "    DOCUMENT TEXT:\n",
    "    {context}\n",
    "\n",
    "    {format_instructions}\n",
    "\n",
    "    Return ONLY valid JSON following the exact schema above.\n",
    "    \"\"\"),\n",
    "    input_variables=[\"context\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0e52d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thebi\\Desktop\\DocsGuide\\src\\projenv\\Lib\\site-packages\\pydantic\\json_schema.py:2442: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=True, description='List of उपदफा नम्बर of the content if not present'),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      "c:\\Users\\thebi\\Desktop\\DocsGuide\\src\\projenv\\Lib\\site-packages\\pydantic\\json_schema.py:2442: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=True, description='List of 1-2 tags from: eligibility & requirements, procedure, recommendation, legal, special case, correction & modification'),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      "c:\\Users\\thebi\\Desktop\\DocsGuide\\src\\projenv\\Lib\\site-packages\\pydantic\\json_schema.py:2442: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=True, description='List of mentioned Dafa or Upadafa numbers empty if none'),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n"
     ]
    }
   ],
   "source": [
    "prompt3 = PromptTemplate(\n",
    "    template=textwrap.dedent(\"\"\"\n",
    "    You are an expert legal document analyzer specialized in Nepali legal and administrative documents. \n",
    "    Your task is to extract, chunk, and structure information from the Nepal Citizenship FAQs PDF\n",
    "    into a JSON-ready schema suitable for vector database insertion.\n",
    "                             \n",
    "      a) tag: Assign maximum of two tags from the list below based on content meaning:\n",
    "        * \"eligibility & requirements\" (योग्यता र आवश्यक कागजातहरू): Age, relationship, residence, or document requirements\n",
    "        * \"procedure\" (प्रक्रिया): Steps for obtaining citizenship, application process, or office procedures\n",
    "        * \"recommendation\" (सिफारिस/मुचुल्का): Recommendations, certificates, or identification from ward or authority\n",
    "        * \"legal\" (कानुनी व्यवस्था र दण्ड): Legal provisions, rules, penalties, or implementation clauses\n",
    "        * \"special case\" (विशेष अवस्था): Exceptional or unusual citizenship circumstances\n",
    "        * \"correction & modification\" (संशोधन र सुधार): Name, surname, or birth-date corrections and related modifications\n",
    "      c) references: No references for this document\n",
    "      d) section: No section names                                      \n",
    "      e) Split semantically into chunks with each question and answer (one chunk equals one question and answer)\n",
    "                             \n",
    "      f) For each chunk include source_type:\"Citizenship_Faqs\" and source_link:\"https://www.moha.gov.np/en/page/citizenship-10\" in schema\n",
    "\n",
    "    g)The `\"content\"` must be written in clear, formal Nepali and be semantically complete — it should answer standalone queries. Write exact content given wthout any summarization or modification(only modified worng unicodes)\n",
    "\n",
    "    DOCUMENT TEXT:\n",
    "    {context}\n",
    "\n",
    "    {format_instructions}\n",
    "\n",
    "    Return ONLY valid JSON following the exact schema above.\n",
    "    \"\"\"),\n",
    "    input_variables=[\"context\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec467529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded text length: 14984 characters\n",
      "First 500 characters:\n",
      "नेपाल नागरिकता ऐन, २०६३ \n",
      " \n",
      " प ्रमाणीकरण र प्रकाशन मिति \n",
      " २०६३।८।१० \n",
      "संशोधन गर्ने ऐन\n",
      " \n",
      "केही नेपाल ऐनलाई संशोधन गर्ने ऐन, २०६४ २०६४।५।९ \n",
      "नेपाल नागरिकता (पहिलो संशोधन) अध्यादेश, २०६९ २०६९।१२।२९ \n",
      " \n",
      "२०६३ सालको ऐन नं. २५ \n",
      "नागरिकता सम्बन्धी नेपाल कानूनलाई संशोधन र एकीकरण गर्न बनेको ऐन \n",
      "प्रस्तावना : ए ेतिहासिक जनआन्दोलनको परिणाम स्वरुप न ेपालको सार्वभौमसत्ता नेपाली जनतामा \n",
      "निहित रहेको र राज्यशक्तिका े स्रोत नेपाली जनता न ै रहेको विद्यमान अवस्थामा विगतमा न ेपाली \n",
      "नागरिकहरुले नागरिकताको प्रमाणपत्र प्राप्त\n",
      "\n",
      "============================================================\n",
      "\n",
      "✅ Successfully extracted structured chunks.\n",
      "Total chunks found: 53\n",
      "\n",
      "✅ Saved 53 chunks to data/citizenship_act_chunks_multi.json\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    full_text = load_pdf(\"../../data/raw/citizenship/citizenship_act_nepali.pdf\")\n",
    "    # full_text = load_pdf(\"../../data/raw/citizenship/citizenship_documents.pdf\")\n",
    "    # full_text = load_pdf(\"../../data/raw/citizenship/citizenship_faqs.pdf\")\n",
    "    print(f\"Loaded text length: {len(full_text)} characters\")\n",
    "    print(f\"First 500 characters:\\n{full_text[:500]}\")\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "    try:\n",
    "        chain = prompt_multi | llm | parser\n",
    "        response = chain.invoke({\"context\": full_text})\n",
    "\n",
    "        print(\"✅ Successfully extracted structured chunks.\")\n",
    "        print(f\"Total chunks found: {len(response.get('chunks', []))}\")\n",
    "\n",
    "        # Save to file\n",
    "        filename = \"data/citizenship_act_chunks_multi.json\"\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(response, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        print(f\"\\n✅ Saved {len(response.get('chunks', []))} chunks to {filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projenv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
